{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Target Label:9\n",
      "No of target images:200\n",
      "Epoch 1, Average Sinkhorn loss: 9271.09765625\n",
      "Epoch 2, Average Sinkhorn loss: 9255.0703125\n",
      "Epoch 3, Average Sinkhorn loss: 9252.1484375\n",
      "Epoch 4, Average Sinkhorn loss: 9247.1044921875\n",
      "Epoch 5, Average Sinkhorn loss: 9244.13671875\n",
      "Epoch 6, Average Sinkhorn loss: 9243.0244140625\n",
      "Epoch 7, Average Sinkhorn loss: 9242.146484375\n",
      "Epoch 8, Average Sinkhorn loss: 9241.0302734375\n",
      "Epoch 9, Average Sinkhorn loss: 9239.998046875\n",
      "Epoch 10, Average Sinkhorn loss: 9239.4033203125\n",
      "Top 10 weights, their indices, and corresponding labels:\n",
      "Weight: 0.019431760534644127, Index: 3189, Label: 4\n",
      "Weight: 0.018872834742069244, Index: 1140, Label: 4\n",
      "Weight: 0.013660362921655178, Index: 2342, Label: 4\n",
      "Weight: 0.009914053604006767, Index: 3590, Label: 0\n",
      "Weight: 0.009910528548061848, Index: 3127, Label: 0\n",
      "Weight: 0.0093167619779706, Index: 2934, Label: 4\n",
      "Weight: 0.008644971996545792, Index: 2155, Label: 3\n",
      "Weight: 0.008335231803357601, Index: 400, Label: 5\n",
      "Weight: 0.008183766156435013, Index: 1424, Label: 2\n",
      "Weight: 0.007919984869658947, Index: 1779, Label: 6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from geomloss import SamplesLoss\n",
    "from torch import optim\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from geomloss import SamplesLoss\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "# Define a function to project weights to a simplex\n",
    "def project_to_simplex(weights):\n",
    "    return torch.clamp(weights, min=0) / torch.sum(weights)\n",
    "\n",
    "def project_simplex(v):\n",
    "        \"\"\"\n",
    "        v: PyTorch Tensor to be projected to a simplex\n",
    "\n",
    "        Returns:\n",
    "        w: PyTorch Tensor simplex projection of v\n",
    "        \"\"\"\n",
    "        z = 1\n",
    "        orig_shape = v.shape\n",
    "        v = v.view(1, -1)\n",
    "        shape = v.shape\n",
    "        with torch.no_grad():\n",
    "            mu = torch.sort(v, dim=1)[0]\n",
    "            mu = torch.flip(mu, dims=(1,))\n",
    "            cum_sum = torch.cumsum(mu, dim=1)\n",
    "            j = torch.unsqueeze(torch.arange(1, shape[1] + 1, dtype=mu.dtype, device=mu.device), 0)\n",
    "            rho = torch.sum(mu * j - cum_sum + z > 0.0, dim=1, keepdim=True) - 1.\n",
    "            rho = rho.to(int)\n",
    "            max_nn = cum_sum[torch.arange(shape[0]), rho[:, 0]]\n",
    "            theta = (torch.unsqueeze(max_nn, -1) - z) / (rho.type(max_nn.dtype) + 1)\n",
    "            w = torch.clamp(v - theta, min=0.0).view(orig_shape)\n",
    "            return w\n",
    "        \n",
    "transform = transforms.Compose(\n",
    "    [transforms.Grayscale(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "cifar_trainset = CIFAR10(root='data/', download=True, transform=transform)\n",
    "subset = torch.utils.data.Subset(cifar_trainset, range(42000))\n",
    "unlabeled, target = torch.utils.data.random_split(subset, [40000, 2000])\n",
    "\n",
    "# Filter target dataset to include only one label, e.g., 0\n",
    "target_images, target_labels = zip(*target)\n",
    "label_to_keep = 9\n",
    "print(\"Target Label:{}\".format(label_to_keep))\n",
    "filtered_target_indices = [i for i, label in enumerate(target_labels) if label == label_to_keep]\n",
    "target_images_org = [target_images[i] for i in filtered_target_indices]\n",
    "target_images = torch.stack(target_images_org)\n",
    "print(\"No of target images:{}\".format(target_images.shape[0]))\n",
    "\n",
    "unlabeled_images, unlabeled_labels = zip(*unlabeled)\n",
    "unlabeled_images = torch.stack(unlabeled_images)\n",
    "unlabeled_loader = DataLoader(list(zip(unlabeled_images, unlabeled_labels)), batch_size=4000, shuffle=False)\n",
    "\n",
    "target_loader = DataLoader(target_images, batch_size=len(target_images), shuffle=False)\n",
    "\n",
    "# Create a loss function using GeomLoss\n",
    "sinkhorn_loss = SamplesLoss(loss=\"sinkhorn\", p=2, blur=0.01)\n",
    "\n",
    "# Initialize weights for the unlabeled_images\n",
    "weights_unlabeled = torch.full((len(unlabeled), 1), 1.0 / len(unlabeled), requires_grad=True)\n",
    "weights_target = torch.full((len(target_images), 1), 1.0 / len(target), requires_grad=False)\n",
    "\n",
    "# Define an optimizer\n",
    "#optimizer = optim.SGD([weights_unlabeled], lr=0.001)\n",
    "optimizer = optim.Adam([weights_unlabeled], lr=0.01)\n",
    "\n",
    "# Loop over the datasets 10 times\n",
    "for epoch in range(10):\n",
    "\n",
    "    losses = []\n",
    "    weights_unlabeled.grad = None  # Reset gradients at the beginning of each epoch\n",
    "\n",
    "    for batch_idx, ((unlabeled_images, _),target_images) in enumerate(zip(unlabeled_loader, target_loader)):\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "\n",
    "        # Select the weights for the current batch\n",
    "        unlabeled_images = unlabeled_images[:,0,:,:]\n",
    "        target_images = target_images[:,0,:,:]\n",
    "        weights_batch = weights_unlabeled[batch_idx * unlabeled_loader.batch_size : (batch_idx + 1) * unlabeled_loader.batch_size]\n",
    "        weights_batch = weights_batch.clone() / weights_batch.sum()\n",
    "\n",
    "        # Reshape the images to be 1D tensors\n",
    "        unlabeled_images = unlabeled_images.view(unlabeled_images.shape[0], -1)\n",
    "        target_images = target_images.view(target_images.shape[0], -1)\n",
    "\n",
    "\n",
    "        # Compute Sinkhorn loss\n",
    "        loss = sinkhorn_loss(weights_batch,unlabeled_images.view(unlabeled_images.shape[0], -1), weights_target,\n",
    "                             target_images.view(target_images.shape[0], -1),\n",
    "                             )\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Compute gradients for the loss\n",
    "        loss.backward()  # Gradients are accumulated over mini-batches\n",
    "\n",
    "    # Average the loss over all mini-batches\n",
    "    loss_avg = sum(losses) / len(losses)\n",
    "\n",
    "    # Update the weights based on the accumulated gradients\n",
    "    optimizer.step()\n",
    "\n",
    "    # Project the weights to a simplex\n",
    "    with torch.no_grad():\n",
    "        weights_unlabeled.data = project_simplex(weights_unlabeled.data)\n",
    "    \n",
    "    #weights_unlabeled = weights_unlabeled_new.clone().detach().requires_grad_(True)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Average Sinkhorn loss: {loss_avg}\")\n",
    "\n",
    "# Sort the weights in descending order and print the non-zero weights\n",
    "sorted_weights, indices = torch.sort(weights_unlabeled.flatten(), descending=True)\n",
    "top_weights = sorted_weights[:10]\n",
    "top_indices = indices[:10]\n",
    "\n",
    "# Retrieve the labels of the images corresponding to the top indices\n",
    "top_labels = [unlabeled_labels[idx] for idx in top_indices]\n",
    "\n",
    "print(\"Top 10 weights, their indices, and corresponding labels:\")\n",
    "for weight, idx, label in zip(top_weights, top_indices, top_labels):\n",
    "    print(f\"Weight: {weight}, Index: {idx}, Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Target Label:9\n",
      "No of target images:91\n",
      "Epoch 1, Average Sinkhorn loss: 11295.7626953125\n",
      "Epoch 2, Average Sinkhorn loss: 11267.4140625\n",
      "Epoch 3, Average Sinkhorn loss: 11240.3623046875\n",
      "Epoch 4, Average Sinkhorn loss: 11225.4228515625\n",
      "Epoch 5, Average Sinkhorn loss: 11214.7158203125\n",
      "Epoch 6, Average Sinkhorn loss: 11206.5166015625\n",
      "Epoch 7, Average Sinkhorn loss: 11200.021484375\n",
      "Epoch 8, Average Sinkhorn loss: 11194.755859375\n",
      "Epoch 9, Average Sinkhorn loss: 11190.2275390625\n",
      "Epoch 10, Average Sinkhorn loss: 11186.5927734375\n",
      "Top 10 weights, their indices, and corresponding labels:\n",
      "Weight: 0.01211019791662693, Index: 672, Label: 9\n",
      "Weight: 0.011650919914245605, Index: 2267, Label: 9\n",
      "Weight: 0.01039084792137146, Index: 728, Label: 9\n",
      "Weight: 0.010268377140164375, Index: 1855, Label: 1\n",
      "Weight: 0.010249389335513115, Index: 1395, Label: 9\n",
      "Weight: 0.010145265609025955, Index: 3802, Label: 9\n",
      "Weight: 0.01006278581917286, Index: 496, Label: 1\n",
      "Weight: 0.009988902136683464, Index: 2081, Label: 8\n",
      "Weight: 0.009909534826874733, Index: 1401, Label: 9\n",
      "Weight: 0.00984535925090313, Index: 3611, Label: 9\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from geomloss import SamplesLoss\n",
    "from torch import optim\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "# Define a function to project weights to a simplex\n",
    "def project_simplex(v):\n",
    "    z = 1\n",
    "    orig_shape = v.shape\n",
    "    v = v.view(1, -1)\n",
    "    shape = v.shape\n",
    "    with torch.no_grad():\n",
    "        mu = torch.sort(v, dim=1)[0]\n",
    "        mu = torch.flip(mu, dims=(1,))\n",
    "        cum_sum = torch.cumsum(mu, dim=1)\n",
    "        j = torch.unsqueeze(torch.arange(1, shape[1] + 1, dtype=mu.dtype, device=mu.device), 0)\n",
    "        rho = torch.sum(mu * j - cum_sum + z > 0.0, dim=1, keepdim=True) - 1.\n",
    "        rho = rho.to(int)\n",
    "        max_nn = cum_sum[torch.arange(shape[0]), rho[:, 0]]\n",
    "        theta = (torch.unsqueeze(max_nn, -1) - z) / (rho.type(max_nn.dtype) + 1)\n",
    "        w = torch.clamp(v - theta, min=0.0).view(orig_shape)\n",
    "        return w\n",
    "        \n",
    "transform = transforms.Compose(\n",
    "    [transforms.Grayscale(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "cifar_trainset = CIFAR10(root='data/', download=True, transform=transform)\n",
    "subset = torch.utils.data.Subset(cifar_trainset, range(42000))\n",
    "unlabeled, remaining = torch.utils.data.random_split(subset, [40000, 2000])\n",
    "\n",
    "# split remaining into target and private\n",
    "target, private = torch.utils.data.random_split(remaining, [1000, 1000])\n",
    "\n",
    "# Filter target dataset to include only one label, e.g., 0\n",
    "target_images, target_labels = zip(*target)\n",
    "label_to_keep = 9\n",
    "print(\"Target Label:{}\".format(label_to_keep))\n",
    "filtered_target_indices = [i for i, label in enumerate(target_labels) if label == label_to_keep]\n",
    "target_images_org = [target_images[i] for i in filtered_target_indices]\n",
    "target_images = torch.stack(target_images_org)\n",
    "print(\"No of target images:{}\".format(target_images.shape[0]))\n",
    "\n",
    "unlabeled_images, unlabeled_labels = zip(*unlabeled)\n",
    "unlabeled_images = torch.stack(unlabeled_images)\n",
    "unlabeled_loader = DataLoader(list(zip(unlabeled_images, unlabeled_labels)), batch_size=4000, shuffle=False)\n",
    "\n",
    "target_loader = DataLoader(target_images, batch_size=len(target_images), shuffle=False)\n",
    "\n",
    "# Filter private dataset to exclude label_to_keep\n",
    "private_images, private_labels = zip(*private)\n",
    "filtered_private_indices = [i for i, label in enumerate(private_labels) if label != label_to_keep]\n",
    "private_images_org = [private_images[i] for i in filtered_private_indices]\n",
    "private_images = torch.stack(private_images_org)\n",
    "\n",
    "private_loader = DataLoader(private_images, batch_size=len(private_images), shuffle=False)\n",
    "\n",
    "# Create a loss function using GeomLoss\n",
    "sinkhorn_loss = SamplesLoss(loss=\"sinkhorn\", p=2, blur=0.01)\n",
    "\n",
    "# Initialize weights for the unlabeled_images and private_images\n",
    "weights_unlabeled = torch.full((len(unlabeled), 1), 1.0 / len(unlabeled), requires_grad=True)\n",
    "weights_target = torch.full((len(target_images), 1), 1.0 / len(target), requires_grad=False)\n",
    "weights_private = torch.full((len(private_images), 1), 1.0 / len(private), requires_grad=False)\n",
    "\n",
    "# Define an optimizer\n",
    "optimizer = optim.Adam([weights_unlabeled], lr=0.01)\n",
    "\n",
    "# Loop over the datasets 10 times\n",
    "for epoch in range(10):\n",
    "\n",
    "    losses = []\n",
    "    weights_unlabeled.grad = None  # Reset gradients at the beginning of each epoch\n",
    "\n",
    "    for batch_idx, ((unlabeled_images, _), target_images, private_images) in enumerate(zip(unlabeled_loader, target_loader, private_loader)):\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "\n",
    "        # Select the weights for the current batch\n",
    "        unlabeled_images = unlabeled_images[:,0,:,:]\n",
    "        target_images = target_images[:,0,:,:]\n",
    "        private_images = private_images[:,0,:,:]\n",
    "        weights_batch = weights_unlabeled[batch_idx * unlabeled_loader.batch_size : (batch_idx + 1) * unlabeled_loader.batch_size]\n",
    "        weights_batch = weights_batch.clone() / weights_batch.sum()\n",
    "\n",
    "        # Reshape the images to be 1D tensors\n",
    "        unlabeled_images = unlabeled_images.view(unlabeled_images.shape[0], -1)\n",
    "        target_images = target_images.view(target_images.shape[0], -1)\n",
    "        private_images = private_images.view(private_images.shape[0], -1)\n",
    "\n",
    "        # Compute Sinkhorn loss\n",
    "        loss_unlabeled_target = sinkhorn_loss(weights_batch, unlabeled_images, weights_target, target_images)\n",
    "        loss_unlabeled_private = sinkhorn_loss(weights_batch, unlabeled_images, weights_private, private_images)\n",
    "        loss_private_target = sinkhorn_loss(weights_private, private_images, weights_target, target_images)\n",
    "\n",
    "        loss = loss_unlabeled_target - loss_unlabeled_private + 0.2*loss_private_target\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Compute gradients for the loss\n",
    "        loss.backward()  # Gradients are accumulated over mini-batches\n",
    "\n",
    "    # Average the loss over all mini-batches\n",
    "    loss_avg = sum(losses) / len(losses)\n",
    "\n",
    "    # Update the weights based on the accumulated gradients\n",
    "    optimizer.step()\n",
    "\n",
    "    # Project the weights to a simplex\n",
    "    with torch.no_grad():\n",
    "        weights_unlabeled.data = project_simplex(weights_unlabeled.data)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Average Sinkhorn loss: {loss_avg}\")\n",
    "\n",
    "# Sort the weights in descending order and print the non-zero weights\n",
    "sorted_weights, indices = torch.sort(weights_unlabeled.flatten(), descending=True)\n",
    "top_weights = sorted_weights[:10]\n",
    "top_indices = indices[:10]\n",
    "\n",
    "# Retrieve the labels of the images corresponding to the top indices\n",
    "top_labels = [unlabeled_labels[idx] for idx in top_indices]\n",
    "\n",
    "print(\"Top 10 weights, their indices, and corresponding labels:\")\n",
    "for weight, idx, label in zip(top_weights, top_indices, top_labels):\n",
    "    print(f\"Weight: {weight}, Index: {idx}, Label: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 weights, their indices, and corresponding labels:\n",
      "Weight: 0.01211019791662693, Index: 672, Label: 9\n",
      "Weight: 0.011650919914245605, Index: 2267, Label: 9\n",
      "Weight: 0.01039084792137146, Index: 728, Label: 9\n",
      "Weight: 0.010268377140164375, Index: 1855, Label: 1\n",
      "Weight: 0.010249389335513115, Index: 1395, Label: 9\n",
      "Weight: 0.010145265609025955, Index: 3802, Label: 9\n",
      "Weight: 0.01006278581917286, Index: 496, Label: 1\n",
      "Weight: 0.009988902136683464, Index: 2081, Label: 8\n",
      "Weight: 0.009909534826874733, Index: 1401, Label: 9\n",
      "Weight: 0.00984535925090313, Index: 3611, Label: 9\n",
      "Weight: 0.00944882445037365, Index: 1711, Label: 9\n",
      "Weight: 0.009372292086482048, Index: 1501, Label: 9\n",
      "Weight: 0.009309044107794762, Index: 2154, Label: 8\n",
      "Weight: 0.009260408580303192, Index: 2523, Label: 7\n",
      "Weight: 0.008967723697423935, Index: 1515, Label: 9\n",
      "Weight: 0.008804993703961372, Index: 1114, Label: 1\n",
      "Weight: 0.00873599760234356, Index: 623, Label: 1\n",
      "Weight: 0.008594978600740433, Index: 1156, Label: 9\n",
      "Weight: 0.008469609543681145, Index: 2825, Label: 9\n",
      "Weight: 0.00844268873333931, Index: 2395, Label: 9\n",
      "Weight: 0.008312823250889778, Index: 2666, Label: 9\n",
      "Weight: 0.008178440853953362, Index: 1018, Label: 9\n",
      "Weight: 0.008171990513801575, Index: 1008, Label: 8\n",
      "Weight: 0.008079769089818, Index: 994, Label: 2\n",
      "Weight: 0.008027289062738419, Index: 1584, Label: 9\n",
      "Weight: 0.008015492931008339, Index: 734, Label: 9\n",
      "Weight: 0.007976243272423744, Index: 2145, Label: 9\n",
      "Weight: 0.007906686514616013, Index: 1512, Label: 3\n",
      "Weight: 0.0078095379285514355, Index: 3439, Label: 1\n",
      "Weight: 0.007771770004183054, Index: 340, Label: 9\n",
      "Weight: 0.0076841614209115505, Index: 1872, Label: 9\n",
      "Weight: 0.007675131317228079, Index: 1647, Label: 8\n",
      "Weight: 0.007622657809406519, Index: 1659, Label: 1\n",
      "Weight: 0.007519005332142115, Index: 349, Label: 9\n",
      "Weight: 0.0075059193186461926, Index: 3756, Label: 8\n",
      "Weight: 0.007426038850098848, Index: 646, Label: 9\n",
      "Weight: 0.007299081888049841, Index: 947, Label: 8\n",
      "Weight: 0.007281571161001921, Index: 2519, Label: 9\n",
      "Weight: 0.007276502903550863, Index: 3477, Label: 9\n",
      "Weight: 0.007218868937343359, Index: 2628, Label: 9\n"
     ]
    }
   ],
   "source": [
    "top_weights = sorted_weights[:40]\n",
    "top_indices = indices[:40]\n",
    "\n",
    "# Retrieve the labels of the images corresponding to the top indices\n",
    "top_labels = [unlabeled_labels[idx] for idx in top_indices]\n",
    "\n",
    "print(\"Top 10 weights, their indices, and corresponding labels:\")\n",
    "for weight, idx, label in zip(top_weights, top_indices, top_labels):\n",
    "    print(f\"Weight: {weight}, Index: {idx}, Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
