{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Target Label:9\n",
      "No of target images:200\n",
      "Epoch 1, Average Sinkhorn loss: 9271.09765625\n",
      "Epoch 2, Average Sinkhorn loss: 9255.0703125\n",
      "Epoch 3, Average Sinkhorn loss: 9252.1484375\n",
      "Epoch 4, Average Sinkhorn loss: 9247.1044921875\n",
      "Epoch 5, Average Sinkhorn loss: 9244.13671875\n",
      "Epoch 6, Average Sinkhorn loss: 9243.0244140625\n",
      "Epoch 7, Average Sinkhorn loss: 9242.146484375\n",
      "Epoch 8, Average Sinkhorn loss: 9241.0302734375\n",
      "Epoch 9, Average Sinkhorn loss: 9239.998046875\n",
      "Epoch 10, Average Sinkhorn loss: 9239.4033203125\n",
      "Top 10 weights, their indices, and corresponding labels:\n",
      "Weight: 0.019431760534644127, Index: 3189, Label: 4\n",
      "Weight: 0.018872834742069244, Index: 1140, Label: 4\n",
      "Weight: 0.013660362921655178, Index: 2342, Label: 4\n",
      "Weight: 0.009914053604006767, Index: 3590, Label: 0\n",
      "Weight: 0.009910528548061848, Index: 3127, Label: 0\n",
      "Weight: 0.0093167619779706, Index: 2934, Label: 4\n",
      "Weight: 0.008644971996545792, Index: 2155, Label: 3\n",
      "Weight: 0.008335231803357601, Index: 400, Label: 5\n",
      "Weight: 0.008183766156435013, Index: 1424, Label: 2\n",
      "Weight: 0.007919984869658947, Index: 1779, Label: 6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from geomloss import SamplesLoss\n",
    "from torch import optim\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from geomloss import SamplesLoss\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "# Define a function to project weights to a simplex\n",
    "def project_to_simplex(weights):\n",
    "    return torch.clamp(weights, min=0) / torch.sum(weights)\n",
    "\n",
    "def project_simplex(v):\n",
    "        \"\"\"\n",
    "        v: PyTorch Tensor to be projected to a simplex\n",
    "\n",
    "        Returns:\n",
    "        w: PyTorch Tensor simplex projection of v\n",
    "        \"\"\"\n",
    "        z = 1\n",
    "        orig_shape = v.shape\n",
    "        v = v.view(1, -1)\n",
    "        shape = v.shape\n",
    "        with torch.no_grad():\n",
    "            mu = torch.sort(v, dim=1)[0]\n",
    "            mu = torch.flip(mu, dims=(1,))\n",
    "            cum_sum = torch.cumsum(mu, dim=1)\n",
    "            j = torch.unsqueeze(torch.arange(1, shape[1] + 1, dtype=mu.dtype, device=mu.device), 0)\n",
    "            rho = torch.sum(mu * j - cum_sum + z > 0.0, dim=1, keepdim=True) - 1.\n",
    "            rho = rho.to(int)\n",
    "            max_nn = cum_sum[torch.arange(shape[0]), rho[:, 0]]\n",
    "            theta = (torch.unsqueeze(max_nn, -1) - z) / (rho.type(max_nn.dtype) + 1)\n",
    "            w = torch.clamp(v - theta, min=0.0).view(orig_shape)\n",
    "            return w\n",
    "        \n",
    "transform = transforms.Compose(\n",
    "    [transforms.Grayscale(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "cifar_trainset = CIFAR10(root='data/', download=True, transform=transform)\n",
    "subset = torch.utils.data.Subset(cifar_trainset, range(42000))\n",
    "unlabeled, target = torch.utils.data.random_split(subset, [40000, 2000])\n",
    "\n",
    "# Filter target dataset to include only one label, e.g., 0\n",
    "target_images, target_labels = zip(*target)\n",
    "label_to_keep = 9\n",
    "print(\"Target Label:{}\".format(label_to_keep))\n",
    "filtered_target_indices = [i for i, label in enumerate(target_labels) if label == label_to_keep]\n",
    "target_images_org = [target_images[i] for i in filtered_target_indices]\n",
    "target_images = torch.stack(target_images_org)\n",
    "print(\"No of target images:{}\".format(target_images.shape[0]))\n",
    "\n",
    "unlabeled_images, unlabeled_labels = zip(*unlabeled)\n",
    "unlabeled_images = torch.stack(unlabeled_images)\n",
    "unlabeled_loader = DataLoader(list(zip(unlabeled_images, unlabeled_labels)), batch_size=4000, shuffle=False)\n",
    "\n",
    "target_loader = DataLoader(target_images, batch_size=len(target_images), shuffle=False)\n",
    "\n",
    "# Create a loss function using GeomLoss\n",
    "sinkhorn_loss = SamplesLoss(loss=\"sinkhorn\", p=2, blur=0.01)\n",
    "\n",
    "# Initialize weights for the unlabeled_images\n",
    "weights_unlabeled = torch.full((len(unlabeled), 1), 1.0 / len(unlabeled), requires_grad=True)\n",
    "weights_target = torch.full((len(target_images), 1), 1.0 / len(target), requires_grad=False)\n",
    "\n",
    "# Define an optimizer\n",
    "#optimizer = optim.SGD([weights_unlabeled], lr=0.001)\n",
    "optimizer = optim.Adam([weights_unlabeled], lr=0.01)\n",
    "\n",
    "# Loop over the datasets 10 times\n",
    "for epoch in range(10):\n",
    "\n",
    "    losses = []\n",
    "    weights_unlabeled.grad = None  # Reset gradients at the beginning of each epoch\n",
    "\n",
    "    for batch_idx, ((unlabeled_images, _),target_images) in enumerate(zip(unlabeled_loader, target_loader)):\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "\n",
    "        # Select the weights for the current batch\n",
    "        unlabeled_images = unlabeled_images[:,0,:,:]\n",
    "        target_images = target_images[:,0,:,:]\n",
    "        weights_batch = weights_unlabeled[batch_idx * unlabeled_loader.batch_size : (batch_idx + 1) * unlabeled_loader.batch_size]\n",
    "        weights_batch = weights_batch.clone() / weights_batch.sum()\n",
    "\n",
    "        # Reshape the images to be 1D tensors\n",
    "        unlabeled_images = unlabeled_images.view(unlabeled_images.shape[0], -1)\n",
    "        target_images = target_images.view(target_images.shape[0], -1)\n",
    "\n",
    "\n",
    "        # Compute Sinkhorn loss\n",
    "        loss = sinkhorn_loss(weights_batch,unlabeled_images.view(unlabeled_images.shape[0], -1), weights_target,\n",
    "                             target_images.view(target_images.shape[0], -1),\n",
    "                             )\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Compute gradients for the loss\n",
    "        loss.backward()  # Gradients are accumulated over mini-batches\n",
    "\n",
    "    # Average the loss over all mini-batches\n",
    "    loss_avg = sum(losses) / len(losses)\n",
    "\n",
    "    # Update the weights based on the accumulated gradients\n",
    "    optimizer.step()\n",
    "\n",
    "    # Project the weights to a simplex\n",
    "    with torch.no_grad():\n",
    "        weights_unlabeled.data = project_simplex(weights_unlabeled.data)\n",
    "    \n",
    "    #weights_unlabeled = weights_unlabeled_new.clone().detach().requires_grad_(True)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Average Sinkhorn loss: {loss_avg}\")\n",
    "\n",
    "# Sort the weights in descending order and print the non-zero weights\n",
    "sorted_weights, indices = torch.sort(weights_unlabeled.flatten(), descending=True)\n",
    "top_weights = sorted_weights[:10]\n",
    "top_indices = indices[:10]\n",
    "\n",
    "# Retrieve the labels of the images corresponding to the top indices\n",
    "top_labels = [unlabeled_labels[idx] for idx in top_indices]\n",
    "\n",
    "print(\"Top 10 weights, their indices, and corresponding labels:\")\n",
    "for weight, idx, label in zip(top_weights, top_indices, top_labels):\n",
    "    print(f\"Weight: {weight}, Index: {idx}, Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Target Label:9\n",
      "No of target and private images:493\n",
      "Epoch 1, Average Sinkhorn loss: 18639.896484375\n",
      "Epoch 2, Average Sinkhorn loss: 18618.90234375\n",
      "Epoch 3, Average Sinkhorn loss: 18660.529296875\n",
      "Epoch 4, Average Sinkhorn loss: 18647.70703125\n",
      "Epoch 5, Average Sinkhorn loss: 18643.46484375\n",
      "Epoch 6, Average Sinkhorn loss: 18632.1328125\n",
      "Epoch 7, Average Sinkhorn loss: 18633.99609375\n",
      "Epoch 8, Average Sinkhorn loss: 18643.685546875\n",
      "Epoch 9, Average Sinkhorn loss: 18637.29296875\n",
      "Epoch 10, Average Sinkhorn loss: 18627.28515625\n",
      "Epoch 11, Average Sinkhorn loss: 18619.453125\n",
      "Epoch 12, Average Sinkhorn loss: 18617.82421875\n",
      "Epoch 13, Average Sinkhorn loss: 18614.515625\n",
      "Epoch 14, Average Sinkhorn loss: 18610.994140625\n",
      "Epoch 15, Average Sinkhorn loss: 18609.37109375\n",
      "Epoch 16, Average Sinkhorn loss: 18606.986328125\n",
      "Epoch 17, Average Sinkhorn loss: 18606.1015625\n",
      "Epoch 18, Average Sinkhorn loss: 18603.21875\n",
      "Epoch 19, Average Sinkhorn loss: 18603.29296875\n",
      "Epoch 20, Average Sinkhorn loss: 18600.6171875\n",
      "Epoch 21, Average Sinkhorn loss: 18600.05859375\n",
      "Epoch 22, Average Sinkhorn loss: 18599.4609375\n",
      "Epoch 23, Average Sinkhorn loss: 18600.16796875\n",
      "Epoch 24, Average Sinkhorn loss: 18599.2109375\n",
      "Epoch 25, Average Sinkhorn loss: 18599.75390625\n",
      "Epoch 26, Average Sinkhorn loss: 18599.77734375\n",
      "Epoch 27, Average Sinkhorn loss: 18600.62109375\n",
      "Epoch 28, Average Sinkhorn loss: 18599.375\n",
      "Epoch 29, Average Sinkhorn loss: 18598.517578125\n",
      "Epoch 30, Average Sinkhorn loss: 18597.287109375\n",
      "Epoch 31, Average Sinkhorn loss: 18596.1484375\n",
      "Epoch 32, Average Sinkhorn loss: 18597.861328125\n",
      "Epoch 33, Average Sinkhorn loss: 18596.6015625\n",
      "Epoch 34, Average Sinkhorn loss: 18597.228515625\n",
      "Epoch 35, Average Sinkhorn loss: 18596.0703125\n",
      "Epoch 36, Average Sinkhorn loss: 18597.048828125\n",
      "Epoch 37, Average Sinkhorn loss: 18597.07421875\n",
      "Epoch 38, Average Sinkhorn loss: 18594.986328125\n",
      "Epoch 39, Average Sinkhorn loss: 18598.6015625\n",
      "Epoch 40, Average Sinkhorn loss: 18596.138671875\n",
      "Epoch 41, Average Sinkhorn loss: 18596.4921875\n",
      "Epoch 42, Average Sinkhorn loss: 18597.193359375\n",
      "Epoch 43, Average Sinkhorn loss: 18598.583984375\n",
      "Epoch 44, Average Sinkhorn loss: 18597.58984375\n",
      "Epoch 45, Average Sinkhorn loss: 18597.3671875\n",
      "Epoch 46, Average Sinkhorn loss: 18599.3046875\n",
      "Epoch 47, Average Sinkhorn loss: 18597.130859375\n",
      "Epoch 48, Average Sinkhorn loss: 18595.1171875\n",
      "Epoch 49, Average Sinkhorn loss: 18597.94140625\n",
      "Epoch 50, Average Sinkhorn loss: 18597.314453125\n",
      "Epoch 51, Average Sinkhorn loss: 18596.171875\n",
      "Epoch 52, Average Sinkhorn loss: 18596.9140625\n",
      "Epoch 53, Average Sinkhorn loss: 18596.3515625\n",
      "Epoch 54, Average Sinkhorn loss: 18595.81640625\n",
      "Epoch 55, Average Sinkhorn loss: 18598.91796875\n",
      "Epoch 56, Average Sinkhorn loss: 18598.66796875\n",
      "Epoch 57, Average Sinkhorn loss: 18600.017578125\n",
      "Epoch 58, Average Sinkhorn loss: 18599.88671875\n",
      "Epoch 59, Average Sinkhorn loss: 18600.63671875\n",
      "Epoch 60, Average Sinkhorn loss: 18597.12109375\n",
      "Epoch 61, Average Sinkhorn loss: 18596.30078125\n",
      "Epoch 62, Average Sinkhorn loss: 18597.05859375\n",
      "Epoch 63, Average Sinkhorn loss: 18599.306640625\n",
      "Epoch 64, Average Sinkhorn loss: 18596.375\n",
      "Epoch 65, Average Sinkhorn loss: 18596.8671875\n",
      "Epoch 66, Average Sinkhorn loss: 18598.630859375\n",
      "Epoch 67, Average Sinkhorn loss: 18600.95703125\n",
      "Epoch 68, Average Sinkhorn loss: 18598.337890625\n",
      "Epoch 69, Average Sinkhorn loss: 18597.43359375\n",
      "Epoch 70, Average Sinkhorn loss: 18596.439453125\n",
      "Epoch 71, Average Sinkhorn loss: 18597.05078125\n",
      "Epoch 72, Average Sinkhorn loss: 18596.390625\n",
      "Epoch 73, Average Sinkhorn loss: 18599.837890625\n",
      "Epoch 74, Average Sinkhorn loss: 18599.96875\n",
      "Epoch 75, Average Sinkhorn loss: 18605.9140625\n",
      "Epoch 76, Average Sinkhorn loss: 18604.6171875\n",
      "Epoch 77, Average Sinkhorn loss: 18610.4453125\n",
      "Epoch 78, Average Sinkhorn loss: 18607.03125\n",
      "Epoch 79, Average Sinkhorn loss: 18616.24609375\n",
      "Epoch 80, Average Sinkhorn loss: 18615.484375\n",
      "Epoch 81, Average Sinkhorn loss: 18636.248046875\n",
      "Epoch 82, Average Sinkhorn loss: 18635.41015625\n",
      "Epoch 83, Average Sinkhorn loss: 18635.12890625\n",
      "Epoch 84, Average Sinkhorn loss: 18628.484375\n",
      "Epoch 85, Average Sinkhorn loss: 18627.216796875\n",
      "Epoch 86, Average Sinkhorn loss: 18619.826171875\n",
      "Epoch 87, Average Sinkhorn loss: 18631.90625\n",
      "Epoch 88, Average Sinkhorn loss: 18633.31640625\n",
      "Epoch 89, Average Sinkhorn loss: 18646.2265625\n",
      "Epoch 90, Average Sinkhorn loss: 18635.53125\n",
      "Epoch 91, Average Sinkhorn loss: 18628.658203125\n",
      "Epoch 92, Average Sinkhorn loss: 18653.1796875\n",
      "Epoch 93, Average Sinkhorn loss: 18647.20703125\n",
      "Epoch 94, Average Sinkhorn loss: 18641.12109375\n",
      "Epoch 95, Average Sinkhorn loss: 18632.552734375\n",
      "Epoch 96, Average Sinkhorn loss: 18638.640625\n",
      "Epoch 97, Average Sinkhorn loss: 18647.7421875\n",
      "Epoch 98, Average Sinkhorn loss: 18632.90625\n",
      "Epoch 99, Average Sinkhorn loss: 18630.779296875\n",
      "Epoch 100, Average Sinkhorn loss: 18651.126953125\n",
      "Top 10 weights, their indices, and corresponding labels:\n",
      "Weight: 0.07690857350826263, Index: 1010, Label: 6\n",
      "Weight: 0.029555559158325195, Index: 1896, Label: 3\n",
      "Weight: 0.021092109382152557, Index: 918, Label: 0\n",
      "Weight: 0.019614845514297485, Index: 416, Label: 2\n",
      "Weight: 0.018389232456684113, Index: 1862, Label: 9\n",
      "Weight: 0.017912715673446655, Index: 341, Label: 4\n",
      "Weight: 0.017607741057872772, Index: 1830, Label: 4\n",
      "Weight: 0.013910241425037384, Index: 364, Label: 8\n",
      "Weight: 0.01213168352842331, Index: 1958, Label: 9\n",
      "Weight: 0.010820209980010986, Index: 147, Label: 9\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from geomloss import SamplesLoss\n",
    "from torch import optim\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "# Define a function to project weights to a simplex\n",
    "def project_simplex(v):\n",
    "    z = 1\n",
    "    orig_shape = v.shape\n",
    "    v = v.view(1, -1)\n",
    "    shape = v.shape\n",
    "    with torch.no_grad():\n",
    "        mu = torch.sort(v, dim=1)[0]\n",
    "        mu = torch.flip(mu, dims=(1,))\n",
    "        cum_sum = torch.cumsum(mu, dim=1)\n",
    "        j = torch.unsqueeze(torch.arange(1, shape[1] + 1, dtype=mu.dtype, device=mu.device), 0)\n",
    "        rho = torch.sum(mu * j - cum_sum + z > 0.0, dim=1, keepdim=True) - 1.\n",
    "        rho = rho.to(int)\n",
    "        max_nn = cum_sum[torch.arange(shape[0]), rho[:, 0]]\n",
    "        theta = (torch.unsqueeze(max_nn, -1) - z) / (rho.type(max_nn.dtype) + 1)\n",
    "        w = torch.clamp(v - theta, min=0.0).view(orig_shape)\n",
    "        return w\n",
    "        \n",
    "transform = transforms.Compose(\n",
    "    [transforms.Grayscale(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "cifar_trainset = CIFAR10(root='data/', download=True, transform=transform)\n",
    "subset = torch.utils.data.Subset(cifar_trainset, range(50000))\n",
    "unlabeled, remaining = torch.utils.data.random_split(subset, [40000, 10000])\n",
    "\n",
    "# split remaining into target and private\n",
    "target, private = torch.utils.data.random_split(remaining, [5000, 5000])\n",
    "\n",
    "# Filter target dataset to include only one label, e.g., 0\n",
    "target_images, target_labels = zip(*target)\n",
    "label_to_keep = 9\n",
    "print(\"Target Label:{}\".format(label_to_keep))\n",
    "filtered_target_indices = [i for i, label in enumerate(target_labels) if label == label_to_keep]\n",
    "target_images_org = [target_images[i] for i in filtered_target_indices]\n",
    "target_images = torch.stack(target_images_org)\n",
    "print(\"No of target and private images:{}\".format(target_images.shape[0]))\n",
    "\n",
    "unlabeled_images, unlabeled_labels = zip(*unlabeled)\n",
    "unlabeled_images = torch.stack(unlabeled_images)\n",
    "unlabeled_loader = DataLoader(list(zip(unlabeled_images, unlabeled_labels)), batch_size=2000, shuffle=False)\n",
    "\n",
    "target_loader = DataLoader(target_images, batch_size=len(target_images), shuffle=False)\n",
    "\n",
    "# Filter private dataset to exclude label_to_keep\n",
    "private_images, private_labels = zip(*private)\n",
    "filtered_private_indices = [i for i, label in enumerate(private_labels) if label != label_to_keep]\n",
    "private_images_org = [private_images[i] for i in filtered_private_indices]\n",
    "private_images = torch.stack(private_images_org[:len(target_images)])\n",
    "\n",
    "private_loader = DataLoader(private_images, batch_size=len(private_images), shuffle=False)\n",
    "\n",
    "# Create a loss function using GeomLoss\n",
    "sinkhorn_loss = SamplesLoss(loss=\"sinkhorn\", p=2, blur=0.01)\n",
    "\n",
    "# Initialize weights for the unlabeled_images and private_images\n",
    "weights_unlabeled = torch.full((len(unlabeled), 1), 1.0 / len(unlabeled), requires_grad=True)\n",
    "weights_target = torch.full((len(target_images), 1), 1.0 / len(target), requires_grad=False)\n",
    "weights_private = torch.full((len(private_images), 1), 1.0 / len(private), requires_grad=False)\n",
    "\n",
    "# Define an optimizer\n",
    "optimizer = optim.Adam([weights_unlabeled], lr=0.1)\n",
    "\n",
    "# Loop over the datasets 10 times\n",
    "for epoch in range(100):\n",
    "\n",
    "    losses = []\n",
    "    weights_unlabeled.grad = None  # Reset gradients at the beginning of each epoch\n",
    "\n",
    "    for batch_idx, ((unlabeled_images, _), target_images, private_images) in enumerate(zip(unlabeled_loader, target_loader, private_loader)):\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "\n",
    "        # Select the weights for the current batch\n",
    "        unlabeled_images = unlabeled_images[:,0,:,:]\n",
    "        target_images = target_images[:,0,:,:]\n",
    "        private_images = private_images[:,0,:,:]\n",
    "        weights_batch = weights_unlabeled[batch_idx * unlabeled_loader.batch_size : (batch_idx + 1) * unlabeled_loader.batch_size]\n",
    "        weights_batch = weights_batch.clone() / weights_batch.sum()\n",
    "\n",
    "        # Reshape the images to be 1D tensors\n",
    "        unlabeled_images = unlabeled_images.view(unlabeled_images.shape[0], -1)\n",
    "        target_images = target_images.view(target_images.shape[0], -1)\n",
    "        private_images = private_images.view(private_images.shape[0], -1)\n",
    "\n",
    "        # Compute Sinkhorn loss\n",
    "        loss_unlabeled_target = sinkhorn_loss(weights_batch, unlabeled_images, weights_target, target_images)\n",
    "        loss_unlabeled_private = sinkhorn_loss(weights_batch, unlabeled_images, weights_private, private_images)\n",
    "        loss_private_target = sinkhorn_loss(weights_private, private_images, weights_target, target_images)\n",
    "\n",
    "        loss = loss_unlabeled_target + loss_unlabeled_private # - loss_private_target\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Compute gradients for the loss\n",
    "        loss.backward()  # Gradients are accumulated over mini-batches\n",
    "\n",
    "    # Average the loss over all mini-batches\n",
    "    loss_avg = sum(losses) / len(losses)\n",
    "\n",
    "    # Update the weights based on the accumulated gradients\n",
    "    optimizer.step()\n",
    "\n",
    "    # Project the weights to a simplex\n",
    "    with torch.no_grad():\n",
    "        weights_unlabeled.data = project_simplex(weights_unlabeled.data)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Average Sinkhorn loss: {loss_avg}\")\n",
    "\n",
    "# Sort the weights in descending order and print the non-zero weights\n",
    "sorted_weights, indices = torch.sort(weights_unlabeled.flatten(), descending=True)\n",
    "top_weights = sorted_weights[:10]\n",
    "top_indices = indices[:10]\n",
    "\n",
    "# Retrieve the labels of the images corresponding to the top indices\n",
    "top_labels = [unlabeled_labels[idx] for idx in top_indices]\n",
    "\n",
    "print(\"Top 10 weights, their indices, and corresponding labels:\")\n",
    "for weight, idx, label in zip(top_weights, top_indices, top_labels):\n",
    "    print(f\"Weight: {weight}, Index: {idx}, Label: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 weights, their indices, and corresponding labels:\n",
      "Weight: 0.09060194343328476, Index: 656, Label: 9\n",
      "Weight: 0.07091376930475235, Index: 1530, Label: 9\n",
      "Weight: 0.05342164263129234, Index: 300, Label: 9\n",
      "Weight: 0.047572292387485504, Index: 311, Label: 9\n",
      "Weight: 0.0457182377576828, Index: 1379, Label: 1\n",
      "Weight: 0.04495656117796898, Index: 224, Label: 8\n",
      "Weight: 0.04354281350970268, Index: 865, Label: 9\n",
      "Weight: 0.03724737837910652, Index: 1613, Label: 8\n",
      "Weight: 0.035446733236312866, Index: 841, Label: 9\n",
      "Weight: 0.03486665338277817, Index: 1855, Label: 9\n",
      "Weight: 0.031335748732089996, Index: 167, Label: 8\n",
      "Weight: 0.028674567118287086, Index: 729, Label: 3\n",
      "Weight: 0.018840136006474495, Index: 220, Label: 8\n",
      "Weight: 0.018701745197176933, Index: 151, Label: 9\n",
      "Weight: 0.018684063106775284, Index: 278, Label: 9\n",
      "Weight: 0.018663911148905754, Index: 1999, Label: 0\n",
      "Weight: 0.016198843717575073, Index: 907, Label: 1\n",
      "Weight: 0.014517731964588165, Index: 1762, Label: 0\n",
      "Weight: 0.01014022808521986, Index: 430, Label: 9\n",
      "Weight: 0.007733653299510479, Index: 336, Label: 9\n",
      "Weight: 0.005633245687931776, Index: 1345, Label: 8\n",
      "Weight: 0.005393225234001875, Index: 432, Label: 9\n",
      "Weight: 0.0033732063602656126, Index: 1105, Label: 7\n",
      "Weight: 0.001081788563169539, Index: 1749, Label: 8\n",
      "Weight: 0.0007172081968747079, Index: 1097, Label: 9\n",
      "Weight: 0.0002956188400276005, Index: 408, Label: 5\n",
      "Weight: 0.00020034592307638377, Index: 60, Label: 9\n",
      "Weight: 7.772754179313779e-05, Index: 1400, Label: 1\n",
      "Weight: 6.57414275337942e-05, Index: 75, Label: 8\n",
      "Weight: 6.0655165725620463e-05, Index: 551, Label: 1\n",
      "Weight: 5.9436461015138775e-05, Index: 1435, Label: 8\n",
      "Weight: 7.7699023677269e-06, Index: 26678, Label: 3\n",
      "Weight: 7.7699023677269e-06, Index: 26679, Label: 8\n",
      "Weight: 7.7699023677269e-06, Index: 26683, Label: 9\n",
      "Weight: 7.7699023677269e-06, Index: 26677, Label: 9\n",
      "Weight: 7.7699023677269e-06, Index: 26671, Label: 7\n",
      "Weight: 7.7699023677269e-06, Index: 26680, Label: 9\n",
      "Weight: 7.7699023677269e-06, Index: 26681, Label: 3\n",
      "Weight: 7.7699023677269e-06, Index: 26676, Label: 9\n",
      "Weight: 7.7699023677269e-06, Index: 26682, Label: 1\n"
     ]
    }
   ],
   "source": [
    "top_weights = sorted_weights[:40]\n",
    "top_indices = indices[:40]\n",
    "\n",
    "# Retrieve the labels of the images corresponding to the top indices\n",
    "top_labels = [unlabeled_labels[idx] for idx in top_indices]\n",
    "\n",
    "print(\"Top 10 weights, their indices, and corresponding labels:\")\n",
    "for weight, idx, label in zip(top_weights, top_indices, top_labels):\n",
    "    print(f\"Weight: {weight}, Index: {idx}, Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Target Label:9\n",
      "No of target and private images:94\n",
      "Loss unlabeled-target: 9588.6845703125, Loss unlabeled-private: 9574.56640625, Loss private-target: 0.0\n",
      "Epoch 1, Average Sinkhorn loss: 19163.25\n",
      "Loss unlabeled-target: 9573.9892578125, Loss unlabeled-private: 9561.9150390625, Loss private-target: 31.018390655517578\n",
      "Epoch 2, Average Sinkhorn loss: 19104.88671875\n",
      "Loss unlabeled-target: 9580.7509765625, Loss unlabeled-private: 9567.3798828125, Loss private-target: 164.49737548828125\n",
      "Epoch 3, Average Sinkhorn loss: 18983.6328125\n",
      "Loss unlabeled-target: 9587.9638671875, Loss unlabeled-private: 9575.0302734375, Loss private-target: 248.09811401367188\n",
      "Epoch 4, Average Sinkhorn loss: 18914.896484375\n",
      "Loss unlabeled-target: 9594.892578125, Loss unlabeled-private: 9586.37109375, Loss private-target: 318.47088623046875\n",
      "Epoch 5, Average Sinkhorn loss: 18862.79296875\n",
      "Loss unlabeled-target: 9600.84765625, Loss unlabeled-private: 9595.3115234375, Loss private-target: 373.2200622558594\n",
      "Epoch 6, Average Sinkhorn loss: 18822.939453125\n",
      "Loss unlabeled-target: 9605.7158203125, Loss unlabeled-private: 9603.40625, Loss private-target: 420.0396728515625\n",
      "Epoch 7, Average Sinkhorn loss: 18789.08203125\n",
      "Loss unlabeled-target: 9609.330078125, Loss unlabeled-private: 9608.0390625, Loss private-target: 454.6729736328125\n",
      "Epoch 8, Average Sinkhorn loss: 18762.6953125\n",
      "Loss unlabeled-target: 9611.7109375, Loss unlabeled-private: 9611.6083984375, Loss private-target: 481.6903076171875\n",
      "Epoch 9, Average Sinkhorn loss: 18741.630859375\n",
      "Loss unlabeled-target: 9613.416015625, Loss unlabeled-private: 9614.177734375, Loss private-target: 501.95806884765625\n",
      "Epoch 10, Average Sinkhorn loss: 18725.634765625\n",
      "Loss unlabeled-target: 9615.025390625, Loss unlabeled-private: 9615.98046875, Loss private-target: 518.2847900390625\n",
      "Epoch 11, Average Sinkhorn loss: 18712.720703125\n",
      "Loss unlabeled-target: 9616.6328125, Loss unlabeled-private: 9617.4228515625, Loss private-target: 534.4481201171875\n",
      "Epoch 12, Average Sinkhorn loss: 18699.607421875\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from geomloss import SamplesLoss\n",
    "from torch import optim\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "# Define a function to project weights to a simplex\n",
    "def project_simplex(v):\n",
    "    z = 1\n",
    "    orig_shape = v.shape\n",
    "    v = v.view(1, -1)\n",
    "    shape = v.shape\n",
    "    with torch.no_grad():\n",
    "        mu = torch.sort(v, dim=1)[0]\n",
    "        mu = torch.flip(mu, dims=(1,))\n",
    "        cum_sum = torch.cumsum(mu, dim=1)\n",
    "        j = torch.unsqueeze(torch.arange(1, shape[1] + 1, dtype=mu.dtype, device=mu.device), 0)\n",
    "        rho = torch.sum(mu * j - cum_sum + z > 0.0, dim=1, keepdim=True) - 1.\n",
    "        rho = rho.to(int)\n",
    "        max_nn = cum_sum[torch.arange(shape[0]), rho[:, 0]]\n",
    "        theta = (torch.unsqueeze(max_nn, -1) - z) / (rho.type(max_nn.dtype) + 1)\n",
    "        w = torch.clamp(v - theta, min=0.0).view(orig_shape)\n",
    "        return w\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "cifar_trainset = CIFAR10(root='data/', download=True, transform=transform)\n",
    "subset = torch.utils.data.Subset(cifar_trainset, range(42000))\n",
    "unlabeled, remaining = torch.utils.data.random_split(subset, [40000, 2000])\n",
    "\n",
    "# split remaining into target and private\n",
    "target, private = torch.utils.data.random_split(remaining, [1000, 1000])\n",
    "\n",
    "# Filter target dataset to include only one label, e.g., 0\n",
    "target_images, target_labels = zip(*target)\n",
    "label_to_keep = 9\n",
    "print(\"Target Label:{}\".format(label_to_keep))\n",
    "filtered_target_indices = [i for i, label in enumerate(target_labels) if label == label_to_keep]\n",
    "target_images_org = [target_images[i] for i in filtered_target_indices]\n",
    "target_images = torch.stack(target_images_org)\n",
    "print(\"No of target and private images:{}\".format(target_images.shape[0]))\n",
    "\n",
    "unlabeled_images, unlabeled_labels = zip(*unlabeled)\n",
    "unlabeled_images = torch.stack(unlabeled_images)\n",
    "unlabeled_loader = DataLoader(list(zip(unlabeled_images, unlabeled_labels)), batch_size=4000, shuffle=False)\n",
    "\n",
    "target_loader = DataLoader(target_images, batch_size=len(target_images), shuffle=False)\n",
    "\n",
    "# Filter private dataset to exclude label_to_keep\n",
    "private_images, private_labels = zip(*private)\n",
    "filtered_private_indices = [i for i, label in enumerate(private_labels) if label != label_to_keep]\n",
    "private_images_org = [private_images[i] for i in filtered_private_indices]\n",
    "private_images = torch.stack(private_images_org[:len(target_images)])\n",
    "\n",
    "private_loader = DataLoader(private_images, batch_size=len(private_images), shuffle=False)\n",
    "\n",
    "# Create a loss function using GeomLoss\n",
    "sinkhorn_loss = SamplesLoss(loss=\"sinkhorn\", p=2, blur=0.01)\n",
    "\n",
    "# Initialize weights for the unlabeled_images for target and private\n",
    "weights_unlabeled_target = torch.full((len(unlabeled), 1), 1.0 / len(unlabeled), requires_grad=True)\n",
    "weights_unlabeled_private = torch.full((len(unlabeled), 1), 1.0 / len(unlabeled), requires_grad=True)\n",
    "weights_target = torch.full((len(target_images), 1), 1.0 / len(target), requires_grad=False)\n",
    "weights_private = torch.full((len(private_images), 1), 1.0 / len(private), requires_grad=False)\n",
    "\n",
    "# Define an optimizer for each set of weights\n",
    "optimizer_target = optim.Adam([weights_unlabeled_target,weights_unlabeled_private], lr=0.01)\n",
    "#optimizer_private = optim.Adam([weights_unlabeled_private], lr=0.01)\n",
    "\n",
    "# Loop over the datasets 10 times\n",
    "for epoch in range(100):\n",
    "\n",
    "    losses = []\n",
    "    weights_unlabeled_target.grad = None  # Reset gradients at the beginning of each epoch\n",
    "    weights_unlabeled_private.grad = None  # Reset gradients at the beginning of each epoch\n",
    "\n",
    "    for batch_idx, ((unlabeled_images, _), target_images, private_images) in enumerate(zip(unlabeled_loader, target_loader, private_loader)):\n",
    "        optimizer_target.zero_grad()  # Reset gradients\n",
    "        \n",
    "\n",
    "        # Select the weights for the current batch\n",
    "        unlabeled_images = unlabeled_images[:,0,:,:]\n",
    "        target_images = target_images[:,0,:,:]\n",
    "        private_images = private_images[:,0,:,:]\n",
    "        weights_batch_target = weights_unlabeled_target[batch_idx * unlabeled_loader.batch_size : (batch_idx + 1) * unlabeled_loader.batch_size]\n",
    "        weights_batch_target = weights_batch_target.clone() / weights_batch_target.sum()\n",
    "        weights_batch_private = weights_unlabeled_private[batch_idx * unlabeled_loader.batch_size : (batch_idx + 1) * unlabeled_loader.batch_size]\n",
    "        weights_batch_private = weights_batch_private.clone() / weights_batch_private.sum()\n",
    "\n",
    "        # Reshape the images to be 1D tensors\n",
    "        unlabeled_images = unlabeled_images.view(unlabeled_images.shape[0], -1)\n",
    "        target_images = target_images.view(target_images.shape[0], -1)\n",
    "        private_images = private_images.view(private_images.shape[0], -1)\n",
    "\n",
    "        # Compute Sinkhorn loss\n",
    "        loss_unlabeled_target = sinkhorn_loss(weights_batch_target, unlabeled_images, weights_target, target_images)\n",
    "        loss_unlabeled_private = sinkhorn_loss(weights_batch_private, unlabeled_images, weights_private, private_images)\n",
    "        loss_private_target = sinkhorn_loss(weights_batch_target, unlabeled_images, weights_batch_private, unlabeled_images)\n",
    "\n",
    "        loss = loss_unlabeled_target + loss_unlabeled_private - loss_private_target\n",
    "        print(f\"Loss unlabeled-target: {loss_unlabeled_target.item()}, Loss unlabeled-private: {loss_unlabeled_private.item()}, Loss private-target: {loss_private_target.item()}\")\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Compute gradients for the loss\n",
    "        loss.backward()  # Gradients are accumulated over mini-batches\n",
    "\n",
    "        # Update the weights based on the accumulated gradients\n",
    "        optimizer_target.step()\n",
    "     \n",
    "\n",
    "    # Average the loss over all mini-batches\n",
    "    loss_avg = sum(losses) / len(losses)\n",
    "   \n",
    "    \n",
    "    \n",
    "   \n",
    "   \n",
    "\n",
    "    # Project the weights to a simplex\n",
    "    with torch.no_grad():\n",
    "        weights_unlabeled_target.data = project_simplex(weights_unlabeled_target.data)\n",
    "        weights_unlabeled_private.data = project_simplex(weights_unlabeled_private.data)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Average Sinkhorn loss: {loss_avg}\")\n",
    "\n",
    "# Sort the weights in descending order and print the non-zero weights\n",
    "sorted_weights_target, indices_target = torch.sort(weights_unlabeled_target.flatten(), descending=True)\n",
    "top_weights_target = sorted_weights_target[:10]\n",
    "top_indices_target = indices_target[:10]\n",
    "\n",
    "sorted_weights_private, indices_private = torch.sort(weights_unlabeled_private.flatten(), descending=True)\n",
    "top_weights_private = sorted_weights_private[:10]\n",
    "top_indices_private = indices_private[:10]\n",
    "\n",
    "# Retrieve the labels of the images corresponding to the top indices\n",
    "top_labels_target = [unlabeled_labels[idx] for idx in top_indices_target]\n",
    "top_labels_private = [unlabeled_labels[idx] for idx in top_indices_private]\n",
    "\n",
    "print(\"Top 10 weights for target, their indices, and corresponding labels:\")\n",
    "for weight, idx, label in zip(top_weights_target, top_indices_target, top_labels_target):\n",
    "    print(f\"Weight: {weight}, Index: {idx}, Label: {label}\")\n",
    "\n",
    "print(\"Top 10 weights for private, their indices, and corresponding labels:\")\n",
    "for weight, idx, label in zip(top_weights_private, top_indices_private, top_labels_private):\n",
    "    print(f\"Weight: {weight}, Index: {idx}, Label: {label}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masking gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Target Label:9\n",
      "No of target and private images:106\n",
      "Loss unlabeled-target: 8991.296875, Loss unlabeled-private: 8973.494140625, Loss private-target: 0.0\n",
      "Epoch 1, Average Sinkhorn loss: 17964.791015625\n",
      "if selected at this epoch, the weights and labels are:\n",
      "Top 10 weights for target, their indices, and corresponding labels:\n",
      "Weight: 0.4358205795288086, Index: 1849, Label: 8\n",
      "Weight: 0.36925792694091797, Index: 672, Label: 1\n",
      "Weight: 0.1286325454711914, Index: 3975, Label: 9\n",
      "Weight: 0.06628894805908203, Index: 3570, Label: 4\n",
      "Weight: 0.0, Index: 26669, Label: 8\n",
      "Weight: 0.0, Index: 26662, Label: 4\n",
      "Weight: 0.0, Index: 26663, Label: 9\n",
      "Weight: 0.0, Index: 26664, Label: 7\n",
      "Weight: 0.0, Index: 26665, Label: 6\n",
      "Weight: 0.0, Index: 26666, Label: 8\n",
      "Top 10 weights for private, their indices, and corresponding labels:\n",
      "Weight: 0.5467453002929688, Index: 3194, Label: 5\n",
      "Weight: 0.44854164123535156, Index: 2377, Label: 3\n",
      "Weight: 0.004714012145996094, Index: 1003, Label: 8\n",
      "Weight: 0.0, Index: 26670, Label: 1\n",
      "Weight: 0.0, Index: 26662, Label: 4\n",
      "Weight: 0.0, Index: 26663, Label: 9\n",
      "Weight: 0.0, Index: 26664, Label: 7\n",
      "Weight: 0.0, Index: 26665, Label: 6\n",
      "Weight: 0.0, Index: 26666, Label: 8\n",
      "Weight: 0.0, Index: 26667, Label: 5\n",
      "Loss unlabeled-target: 9001.291015625, Loss unlabeled-private: 9147.7939453125, Loss private-target: 581.7452392578125\n",
      "Epoch 2, Average Sinkhorn loss: 18149.0859375\n",
      "if selected at this epoch, the weights and labels are:\n",
      "Top 10 weights for target, their indices, and corresponding labels:\n",
      "Weight: 0.43885183334350586, Index: 3728, Label: 6\n",
      "Weight: 0.33016014099121094, Index: 124, Label: 6\n",
      "Weight: 0.12141036987304688, Index: 1862, Label: 6\n",
      "Weight: 0.09644937515258789, Index: 1305, Label: 6\n",
      "Weight: 0.013128995895385742, Index: 510, Label: 6\n",
      "Weight: 0.0, Index: 26671, Label: 4\n",
      "Weight: 0.0, Index: 26665, Label: 6\n",
      "Weight: 0.0, Index: 26666, Label: 8\n",
      "Weight: 0.0, Index: 26667, Label: 5\n",
      "Weight: 0.0, Index: 26663, Label: 9\n",
      "Top 10 weights for private, their indices, and corresponding labels:\n",
      "Weight: 0.18030261993408203, Index: 3039, Label: 4\n",
      "Weight: 0.16329097747802734, Index: 3539, Label: 3\n",
      "Weight: 0.12915992736816406, Index: 571, Label: 0\n",
      "Weight: 0.1225290298461914, Index: 2218, Label: 2\n",
      "Weight: 0.11145496368408203, Index: 2223, Label: 3\n",
      "Weight: 0.09930610656738281, Index: 2303, Label: 0\n",
      "Weight: 0.04507732391357422, Index: 2813, Label: 0\n",
      "Weight: 0.04123973846435547, Index: 83, Label: 2\n",
      "Weight: 0.02903270721435547, Index: 2570, Label: 9\n",
      "Weight: 0.029013633728027344, Index: 1867, Label: 4\n",
      "Loss unlabeled-target: 9075.0830078125, Loss unlabeled-private: 9075.5673828125, Loss private-target: 681.5810546875\n",
      "Epoch 3, Average Sinkhorn loss: 18150.650390625\n",
      "if selected at this epoch, the weights and labels are:\n",
      "Top 10 weights for target, their indices, and corresponding labels:\n",
      "Weight: 0.1685810089111328, Index: 2303, Label: 0\n",
      "Weight: 0.12891292572021484, Index: 571, Label: 0\n",
      "Weight: 0.11606121063232422, Index: 3935, Label: 0\n",
      "Weight: 0.1114811897277832, Index: 993, Label: 2\n",
      "Weight: 0.09326839447021484, Index: 912, Label: 4\n",
      "Weight: 0.08168649673461914, Index: 1245, Label: 2\n",
      "Weight: 0.0732583999633789, Index: 2191, Label: 2\n",
      "Weight: 0.0715789794921875, Index: 3039, Label: 4\n",
      "Weight: 0.04937171936035156, Index: 1977, Label: 4\n",
      "Weight: 0.030094623565673828, Index: 1853, Label: 4\n",
      "Top 10 weights for private, their indices, and corresponding labels:\n",
      "Weight: 0.26975154876708984, Index: 2377, Label: 3\n",
      "Weight: 0.2253570556640625, Index: 1003, Label: 8\n",
      "Weight: 0.1194295883178711, Index: 510, Label: 6\n",
      "Weight: 0.11878490447998047, Index: 3194, Label: 5\n",
      "Weight: 0.08580684661865234, Index: 2462, Label: 0\n",
      "Weight: 0.0852499008178711, Index: 3020, Label: 0\n",
      "Weight: 0.04522991180419922, Index: 3531, Label: 5\n",
      "Weight: 0.018629074096679688, Index: 3205, Label: 6\n",
      "Weight: 0.017740249633789062, Index: 1132, Label: 3\n",
      "Weight: 0.014019012451171875, Index: 425, Label: 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 102\u001b[0m\n\u001b[1;32m    100\u001b[0m loss_unlabeled_target \u001b[39m=\u001b[39m sinkhorn_loss(weights_batch_target, unlabeled_images, weights_target, target_images)\n\u001b[1;32m    101\u001b[0m loss_unlabeled_private \u001b[39m=\u001b[39m sinkhorn_loss(weights_batch_private, unlabeled_images, weights_private, private_images)\n\u001b[0;32m--> 102\u001b[0m loss_private_target \u001b[39m=\u001b[39m sinkhorn_loss(weights_batch_target, unlabeled_images, weights_batch_private, unlabeled_images)\n\u001b[1;32m    104\u001b[0m loss \u001b[39m=\u001b[39m loss_unlabeled_target \u001b[39m+\u001b[39m loss_unlabeled_private \u001b[39m#- loss_private_target\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoss unlabeled-target: \u001b[39m\u001b[39m{\u001b[39;00mloss_unlabeled_target\u001b[39m.\u001b[39mitem()\u001b[39m}\u001b[39;00m\u001b[39m, Loss unlabeled-private: \u001b[39m\u001b[39m{\u001b[39;00mloss_unlabeled_private\u001b[39m.\u001b[39mitem()\u001b[39m}\u001b[39;00m\u001b[39m, Loss private-target: \u001b[39m\u001b[39m{\u001b[39;00mloss_private_target\u001b[39m.\u001b[39mitem()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/workbook/sinkhorn-minibatch/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Projects/workbook/sinkhorn-minibatch/.venv/lib/python3.10/site-packages/geomloss/samples_loss.py:265\u001b[0m, in \u001b[0;36mSamplesLoss.forward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    262\u001b[0m     α, x, β, y \u001b[39m=\u001b[39m α\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m), x\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m), β\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m), y\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m    264\u001b[0m \u001b[39m# Run --------------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m values \u001b[39m=\u001b[39m routines[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss][backend](\n\u001b[1;32m    266\u001b[0m     α,\n\u001b[1;32m    267\u001b[0m     x,\n\u001b[1;32m    268\u001b[0m     β,\n\u001b[1;32m    269\u001b[0m     y,\n\u001b[1;32m    270\u001b[0m     p\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp,\n\u001b[1;32m    271\u001b[0m     blur\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblur,\n\u001b[1;32m    272\u001b[0m     reach\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreach,\n\u001b[1;32m    273\u001b[0m     diameter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdiameter,\n\u001b[1;32m    274\u001b[0m     scaling\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscaling,\n\u001b[1;32m    275\u001b[0m     truncate\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtruncate,\n\u001b[1;32m    276\u001b[0m     cost\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcost,\n\u001b[1;32m    277\u001b[0m     kernel\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel,\n\u001b[1;32m    278\u001b[0m     cluster_scale\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcluster_scale,\n\u001b[1;32m    279\u001b[0m     debias\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdebias,\n\u001b[1;32m    280\u001b[0m     potentials\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpotentials,\n\u001b[1;32m    281\u001b[0m     labels_x\u001b[39m=\u001b[39;49ml_x,\n\u001b[1;32m    282\u001b[0m     labels_y\u001b[39m=\u001b[39;49ml_y,\n\u001b[1;32m    283\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    284\u001b[0m )\n\u001b[1;32m    286\u001b[0m \u001b[39m# Make sure that the output has the correct shape ------------------------------------\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    288\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpotentials\n\u001b[1;32m    289\u001b[0m ):  \u001b[39m# Return some dual potentials (= test functions) sampled on the input measures\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/workbook/sinkhorn-minibatch/.venv/lib/python3.10/site-packages/geomloss/sinkhorn_samples.py:196\u001b[0m, in \u001b[0;36msinkhorn_tensorized\u001b[0;34m(a, x, b, y, p, blur, reach, diameter, scaling, cost, debias, potentials, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m diameter, eps, eps_list, rho \u001b[39m=\u001b[39m scaling_parameters(\n\u001b[1;32m    192\u001b[0m     x, y, p, blur, reach, diameter, scaling\n\u001b[1;32m    193\u001b[0m )\n\u001b[1;32m    195\u001b[0m \u001b[39m# Use an optimal transport solver to retrieve the dual potentials:\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m f_aa, g_bb, g_ab, f_ba \u001b[39m=\u001b[39m sinkhorn_loop(\n\u001b[1;32m    197\u001b[0m     softmin_tensorized,\n\u001b[1;32m    198\u001b[0m     log_weights(a),\n\u001b[1;32m    199\u001b[0m     log_weights(b),\n\u001b[1;32m    200\u001b[0m     C_xx,\n\u001b[1;32m    201\u001b[0m     C_yy,\n\u001b[1;32m    202\u001b[0m     C_xy,\n\u001b[1;32m    203\u001b[0m     C_yx,\n\u001b[1;32m    204\u001b[0m     eps_list,\n\u001b[1;32m    205\u001b[0m     rho,\n\u001b[1;32m    206\u001b[0m     debias\u001b[39m=\u001b[39;49mdebias,\n\u001b[1;32m    207\u001b[0m )\n\u001b[1;32m    209\u001b[0m \u001b[39m# Optimal transport cost:\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[39mreturn\u001b[39;00m sinkhorn_cost(\n\u001b[1;32m    211\u001b[0m     eps,\n\u001b[1;32m    212\u001b[0m     rho,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    221\u001b[0m     potentials\u001b[39m=\u001b[39mpotentials,\n\u001b[1;32m    222\u001b[0m )\n",
      "File \u001b[0;32m~/Projects/workbook/sinkhorn-minibatch/.venv/lib/python3.10/site-packages/geomloss/sinkhorn_divergence.py:483\u001b[0m, in \u001b[0;36msinkhorn_loop\u001b[0;34m(softmin, a_logs, b_logs, C_xxs, C_yys, C_xys, C_yxs, eps_list, rho, jumps, kernel_truncation, truncate, cost, extrapolate, debias, last_extrapolation)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[39m# Line 7: \"coordinate ascent\" on the dual problems -----------------------------\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[39m# N.B.: As discussed in Section 3.3.3 of Jean Feydy's PhD thesis,\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[39m#       we perform \"symmetric\" instead of \"alternate\" updates\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[39m#       Sinkhorn formulas, and update both dual vectors\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[39m#       simultaneously.\u001b[39;00m\n\u001b[1;32m    482\u001b[0m ft_ba \u001b[39m=\u001b[39m damping \u001b[39m*\u001b[39m softmin(eps, C_xy, b_log \u001b[39m+\u001b[39m g_ab \u001b[39m/\u001b[39m eps)  \u001b[39m# b -> a\u001b[39;00m\n\u001b[0;32m--> 483\u001b[0m gt_ab \u001b[39m=\u001b[39m damping \u001b[39m*\u001b[39m softmin(eps, C_yx, a_log \u001b[39m+\u001b[39;49m f_ba \u001b[39m/\u001b[39;49m eps)  \u001b[39m# a -> b\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[39m# See Fig. 3.21 in Jean Feydy's PhD thesis to see the importance\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[39m# of debiasing when the target \"blur\" or \"eps**(1/p)\" value is larger\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[39m# than the average distance between samples x_i, y_j and their neighbours.\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[39mif\u001b[39;00m debias:\n",
      "File \u001b[0;32m~/Projects/workbook/sinkhorn-minibatch/.venv/lib/python3.10/site-packages/geomloss/sinkhorn_samples.py:72\u001b[0m, in \u001b[0;36msoftmin_tensorized\u001b[0;34m(eps, C_xy, h_y)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Soft-C-transform, implemented using dense torch Tensors.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \n\u001b[1;32m     36\u001b[0m \u001b[39mThis routine implements the (soft-)C-transform\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39m        by the points :math:`x_i`.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m B \u001b[39m=\u001b[39m C_xy\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m---> 72\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39meps \u001b[39m*\u001b[39m (h_y\u001b[39m.\u001b[39;49mview(B, \u001b[39m1\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m) \u001b[39m-\u001b[39;49m C_xy \u001b[39m/\u001b[39;49m eps)\u001b[39m.\u001b[39;49mlogsumexp(\u001b[39m2\u001b[39;49m)\u001b[39m.\u001b[39mview(B, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from geomloss import SamplesLoss\n",
    "from torch import optim\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "# Define a function to project weights to a simplex\n",
    "def project_simplex(v):\n",
    "    z = 1\n",
    "    orig_shape = v.shape\n",
    "    v = v.view(1, -1)\n",
    "    shape = v.shape\n",
    "    with torch.no_grad():\n",
    "        mu = torch.sort(v, dim=1)[0]\n",
    "        mu = torch.flip(mu, dims=(1,))\n",
    "        cum_sum = torch.cumsum(mu, dim=1)\n",
    "        j = torch.unsqueeze(torch.arange(1, shape[1] + 1, dtype=mu.dtype, device=mu.device), 0)\n",
    "        rho = torch.sum(mu * j - cum_sum + z > 0.0, dim=1, keepdim=True) - 1.\n",
    "        rho = rho.to(int)\n",
    "        max_nn = cum_sum[torch.arange(shape[0]), rho[:, 0]]\n",
    "        theta = (torch.unsqueeze(max_nn, -1) - z) / (rho.type(max_nn.dtype) + 1)\n",
    "        w = torch.clamp(v - theta, min=0.0).view(orig_shape)\n",
    "        return w\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "cifar_trainset = CIFAR10(root='data/', download=True, transform=transform)\n",
    "subset = torch.utils.data.Subset(cifar_trainset, range(42000))\n",
    "unlabeled, remaining = torch.utils.data.random_split(subset, [40000, 2000])\n",
    "\n",
    "# split remaining into target and private\n",
    "target, private = torch.utils.data.random_split(remaining, [1000, 1000])\n",
    "\n",
    "# Filter target dataset to include only one label, e.g., 0\n",
    "target_images, target_labels = zip(*target)\n",
    "label_to_keep = 9\n",
    "print(\"Target Label:{}\".format(label_to_keep))\n",
    "filtered_target_indices = [i for i, label in enumerate(target_labels) if label == label_to_keep]\n",
    "target_images_org = [target_images[i] for i in filtered_target_indices]\n",
    "target_images = torch.stack(target_images_org)\n",
    "print(\"No of target and private images:{}\".format(target_images.shape[0]))\n",
    "\n",
    "unlabeled_images, unlabeled_labels = zip(*unlabeled)\n",
    "unlabeled_images = torch.stack(unlabeled_images)\n",
    "unlabeled_loader = DataLoader(list(zip(unlabeled_images, unlabeled_labels)), batch_size=4000, shuffle=False)\n",
    "\n",
    "target_loader = DataLoader(target_images, batch_size=len(target_images), shuffle=False)\n",
    "\n",
    "# Filter private dataset to exclude label_to_keep\n",
    "private_images, private_labels = zip(*private)\n",
    "filtered_private_indices = [i for i, label in enumerate(private_labels) if label != label_to_keep]\n",
    "private_images_org = [private_images[i] for i in filtered_private_indices]\n",
    "private_images = torch.stack(private_images_org[:len(target_images)])\n",
    "\n",
    "private_loader = DataLoader(private_images, batch_size=len(private_images), shuffle=False)\n",
    "\n",
    "# Create a loss function using GeomLoss\n",
    "sinkhorn_loss = SamplesLoss(loss=\"sinkhorn\", p=2, blur=0.01)\n",
    "\n",
    "# Initialize weights for the unlabeled_images for target and private\n",
    "weights_unlabeled_target = torch.full((len(unlabeled), 1), 1.0 / len(unlabeled), requires_grad=True)\n",
    "weights_unlabeled_private = torch.full((len(unlabeled), 1), 1.0 / len(unlabeled), requires_grad=True)\n",
    "weights_target = torch.full((len(target_images), 1), 1.0 / len(target), requires_grad=False)\n",
    "weights_private = torch.full((len(private_images), 1), 1.0 / len(private), requires_grad=False)\n",
    "\n",
    "# Define an optimizer for each set of weights\n",
    "optimizer_target = optim.SGD([weights_unlabeled_target,weights_unlabeled_private], lr=0.01)\n",
    "#optimizer_private = optim.Adam([weights_unlabeled_private], lr=0.01)\n",
    "\n",
    "# Loop over the datasets 10 times\n",
    "for epoch in range(100):\n",
    "\n",
    "    losses = []\n",
    "    weights_unlabeled_target.grad = None  # Reset gradients at the beginning of each epoch\n",
    "    weights_unlabeled_private.grad = None  # Reset gradients at the beginning of each epoch\n",
    "\n",
    "    for batch_idx, ((unlabeled_images, _), target_images, private_images) in enumerate(zip(unlabeled_loader, target_loader, private_loader)):\n",
    "        optimizer_target.zero_grad()  # Reset gradients\n",
    "        \n",
    "\n",
    "        # Select the weights for the current batch\n",
    "        unlabeled_images = unlabeled_images[:,0,:,:]\n",
    "        target_images = target_images[:,0,:,:]\n",
    "        private_images = private_images[:,0,:,:]\n",
    "        weights_batch_target = weights_unlabeled_target[batch_idx * unlabeled_loader.batch_size : (batch_idx + 1) * unlabeled_loader.batch_size]\n",
    "        weights_batch_target = weights_batch_target.clone() / weights_batch_target.sum()\n",
    "        weights_batch_private = weights_unlabeled_private[batch_idx * unlabeled_loader.batch_size : (batch_idx + 1) * unlabeled_loader.batch_size]\n",
    "        weights_batch_private = weights_batch_private.clone() / weights_batch_private.sum()\n",
    "\n",
    "        # Reshape the images to be 1D tensors\n",
    "        unlabeled_images = unlabeled_images.view(unlabeled_images.shape[0], -1)\n",
    "        target_images = target_images.view(target_images.shape[0], -1)\n",
    "        private_images = private_images.view(private_images.shape[0], -1)\n",
    "\n",
    "        # Compute Sinkhorn loss\n",
    "        loss_unlabeled_target = sinkhorn_loss(weights_batch_target, unlabeled_images, weights_target, target_images)\n",
    "        loss_unlabeled_private = sinkhorn_loss(weights_batch_private, unlabeled_images, weights_private, private_images)\n",
    "        #loss_private_target = sinkhorn_loss(weights_batch_target, unlabeled_images, weights_batch_private, unlabeled_images)\n",
    "\n",
    "        loss = loss_unlabeled_target + loss_unlabeled_private #- loss_private_target\n",
    "        print(f\"Loss unlabeled-target: {loss_unlabeled_target.item()}, Loss unlabeled-private: {loss_unlabeled_private.item()}, Loss private-target: {loss_private_target.item()}\")\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Compute gradients for the loss\n",
    "        loss.backward()  # Gradients are accumulated over mini-batches\n",
    "\n",
    "        # Create a mask for weights_unlabeled_target and weights_unlabeled_private\n",
    "        '''\n",
    "        mask_target = torch.zeros_like(weights_unlabeled_target)\n",
    "        mask_target[batch_idx * unlabeled_loader.batch_size : (batch_idx + 1) * unlabeled_loader.batch_size] = 1.0\n",
    "        mask_private = torch.zeros_like(weights_unlabeled_private)\n",
    "        mask_private[batch_idx * unlabeled_loader.batch_size : (batch_idx + 1) * unlabeled_loader.batch_size] = 1.0\n",
    "        \n",
    "        # Apply the masks to the gradients\n",
    "        weights_unlabeled_target.grad *= mask_target\n",
    "        weights_unlabeled_private.grad *= mask_private\n",
    "        '''\n",
    "        # Update the weights based on the accumulated gradients\n",
    "        optimizer_target.step()\n",
    "     \n",
    "\n",
    "    # Average the loss over all mini-batches\n",
    "    loss_avg = sum(losses) / len(losses)\n",
    "   \n",
    "    \n",
    "    \n",
    "   \n",
    "   \n",
    "\n",
    "    # Project the weights to a simplex\n",
    "    with torch.no_grad():\n",
    "        weights_unlabeled_target.data = project_simplex(weights_unlabeled_target.data)\n",
    "        weights_unlabeled_private.data = project_simplex(weights_unlabeled_private.data)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Average Sinkhorn loss: {loss_avg}\")\n",
    "\n",
    "    print('if selected at this epoch, the weights and labels are:')\n",
    "\n",
    "    # Sort the weights in descending order and print the non-zero weights\n",
    "    sorted_weights_target, indices_target = torch.sort(weights_unlabeled_target.flatten(), descending=True)\n",
    "    top_weights_target = sorted_weights_target[:10]\n",
    "    top_indices_target = indices_target[:10]\n",
    "\n",
    "    sorted_weights_private, indices_private = torch.sort(weights_unlabeled_private.flatten(), descending=True)\n",
    "    top_weights_private = sorted_weights_private[:10]\n",
    "    top_indices_private = indices_private[:10]\n",
    "\n",
    "    # Retrieve the labels of the images corresponding to the top indices\n",
    "    top_labels_target = [unlabeled_labels[idx] for idx in top_indices_target]\n",
    "    top_labels_private = [unlabeled_labels[idx] for idx in top_indices_private]\n",
    "\n",
    "    print(\"Top 10 weights for target, their indices, and corresponding labels:\")\n",
    "    for weight, idx, label in zip(top_weights_target, top_indices_target, top_labels_target):\n",
    "        print(f\"Weight: {weight}, Index: {idx}, Label: {label}\")\n",
    "\n",
    "    print(\"Top 10 weights for private, their indices, and corresponding labels:\")\n",
    "    for weight, idx, label in zip(top_weights_private, top_indices_private, top_labels_private):\n",
    "        print(f\"Weight: {weight}, Index: {idx}, Label: {label}\")\n",
    "    #if loss is zero or less quit\n",
    "    #if loss_avg <= 0:\n",
    "    #    break\n",
    "\n",
    "\n",
    "# Sort the weights in descending order and print the non-zero weights\n",
    "sorted_weights_target, indices_target = torch.sort(weights_unlabeled_target.flatten(), descending=True)\n",
    "top_weights_target = sorted_weights_target[:10]\n",
    "top_indices_target = indices_target[:10]\n",
    "\n",
    "sorted_weights_private, indices_private = torch.sort(weights_unlabeled_private.flatten(), descending=True)\n",
    "top_weights_private = sorted_weights_private[:10]\n",
    "top_indices_private = indices_private[:10]\n",
    "\n",
    "# Retrieve the labels of the images corresponding to the top indices\n",
    "top_labels_target = [unlabeled_labels[idx] for idx in top_indices_target]\n",
    "top_labels_private = [unlabeled_labels[idx] for idx in top_indices_private]\n",
    "\n",
    "print(\"Top 10 weights for target, their indices, and corresponding labels:\")\n",
    "for weight, idx, label in zip(top_weights_target, top_indices_target, top_labels_target):\n",
    "    print(f\"Weight: {weight}, Index: {idx}, Label: {label}\")\n",
    "\n",
    "print(\"Top 10 weights for private, their indices, and corresponding labels:\")\n",
    "for weight, idx, label in zip(top_weights_private, top_indices_private, top_labels_private):\n",
    "    print(f\"Weight: {weight}, Index: {idx}, Label: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
